{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "warming-discrimination",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adequate-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.path.abspath('../..')\n",
    "if path not in sys.path:\n",
    "    sys.path.insert(0, path)\n",
    "    \n",
    "sys.path\n",
    "\n",
    "from primer3plus.utils import reverse_complement as rc\n",
    "import primer3\n",
    "from aqbt.contrib.uwbf import primer_utils\n",
    "from aqbt import AquariumBuildTools\n",
    "aqtools = AquariumBuildTools.from_toml('creds.secret.toml')\n",
    "aqtools.sessions\n",
    "\n",
    "aq = aqtools.sessions['production']['aquarium']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-edmonton",
   "metadata": {},
   "source": [
    "## Potential Build Trajectories\n",
    "\n",
    "We create every possible build trajectory for a given goal build. Builds are defined as a sorted set of integrant ids to be found in the resulting strain. The sorted set of tuples is known as a **part_hash**. We create a DAG with node ids being a sorted tuple of integrant ids and between these nodes indicating a transformation; plasmid_ids can be found as attributes along the edges.\n",
    "\n",
    "*TODO* Weights will be determined by the availability of integrants\n",
    "*TODO* start node should be provided. If a strain exists, an edge from START to the node should added with `weight=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "going-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = aq.with_cache(timeout=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "vulnerable-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import Hashable, Generator, TypeVar, List, Tuple, Optional, Dict, Callable\n",
    "from pydent import AqSession\n",
    "from pydent import ModelBase\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "Node = Hashable\n",
    "_T = TypeVar('_T')\n",
    "\n",
    "\n",
    "def is_leaf(n: Node, g: nx.DiGraph):\n",
    "    successors = list(g.successors(n))\n",
    "    if successors:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def is_root(n: Node, g: nx.DiGraph):\n",
    "    predecessors = list(g.predecessors(n))\n",
    "    if predecessors:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def iter_leaves(g: nx.DiGraph) -> Generator[Node, None, None]:\n",
    "    for n in g.nodes():\n",
    "        if is_leaf(n, g):\n",
    "            yield n\n",
    "\n",
    "\n",
    "def iter_roots(g: nx.DiGraph) -> Generator[Node, None, None]:\n",
    "    for n in g.nodes():\n",
    "        if is_root(n, g):\n",
    "            yield n\n",
    "\n",
    "\n",
    "def iter_split_sets(arr: List[_T]) -> Tuple[List[_T], _T]:\n",
    "    for i in range(len(arr)):\n",
    "        yield tuple(arr[:i] + arr[i + 1:]), arr[i]\n",
    "\n",
    "\n",
    "class HashFunctions(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def int_list_hash(ids: List[int], prefix: Optional[str] = None) -> Tuple[str, Tuple[int]]:\n",
    "        return prefix, tuple(sorted(ids))\n",
    "\n",
    "\n",
    "def group_by_sample_id(items):\n",
    "    data = {}\n",
    "    for item in items:\n",
    "        data.setdefault(item.sample_id, list())\n",
    "        data[item.sample_id].append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def group_by_object_type_id(items):\n",
    "    data = {}\n",
    "    for item in items:\n",
    "        data.setdefault(item.object_type_id, list())\n",
    "        data[item.object_type_id].append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def is_aq_model(x):\n",
    "    return issubclass(x.__class__, ModelBase)\n",
    "\n",
    "\n",
    "def get_models(sess, x, model):\n",
    "    interface = sess.model_interface(model)\n",
    "    if isinstance(x, int):\n",
    "        res = [interface.find(x)]\n",
    "        if res[0] is None:\n",
    "            raise ValueError(\"Could not find {}\".format(x))\n",
    "    elif isinstance(x, str):\n",
    "        res = [interface.find_by_name(x)]\n",
    "        if res[0] is None:\n",
    "            raise ValueError(\"Could not find {}\".format(x))\n",
    "    elif is_aq_model(x):\n",
    "        res = [x]\n",
    "        if res is None:\n",
    "            raise ValueError\n",
    "    elif isinstance(x, dict):\n",
    "        res = interface.where(x)\n",
    "        if res is None:\n",
    "            raise ValueError\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        res = []\n",
    "        for _x in x:\n",
    "            res.extend(get_models(sess, _x, model))\n",
    "    else:\n",
    "        raise TypeError\n",
    "    return res\n",
    "\n",
    "\n",
    "class LIMSDB(object):\n",
    "    YEAST_OBJECT_TYPES = ['Yeast Glycerol Stock', 'Yeast Plate', 'Yeast Competent Aliquot', 'Yeast Competent Cell']\n",
    "    DNA_OBJECT_TYPES = ['Plasmid Stock', 'Plasmid Glycerol Stock', '1 ng/µL Plasmid Stock', 'Fragment Stock',\n",
    "                        '1 ng/µL Fragment Stock']\n",
    "\n",
    "    def __init__(self, sess: AqSession, strains=None, n=None, timeout: int = 60, progressbar: Callable = tqdm):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sess:\n",
    "        :param strains:\n",
    "        :param n:\n",
    "        :param timeout:\n",
    "        :param progressbar:\n",
    "        \"\"\"\n",
    "        self.progressbar = progressbar\n",
    "        self.sess = sess.with_cache(timeout=timeout)\n",
    "        self.common = {\n",
    "            'sample_types': {\n",
    "                'yeast': self.sess.SampleType.find_by_name('Yeast Strain'),\n",
    "                'plasmid': self.sess.SampleType.find_by_name('Plasmid'),\n",
    "                'fragment': self.sess.SampleType.find_by_name('Fragment'),\n",
    "            },\n",
    "            'object_types': {\n",
    "                'yeast': get_models(self.sess, self.YEAST_OBJECT_TYPES, 'ObjectType'),\n",
    "                'dna': get_models(self.sess, self.DNA_OBJECT_TYPES, 'ObjectType')\n",
    "            }\n",
    "        }\n",
    "        self.prov: nx.DiGraph = self.build_prov_graph(strains=strains, n=n)\n",
    "        self.cache_items()\n",
    "\n",
    "    def node_to_hash_fn(self, x, prefix=None):\n",
    "        node, ndata = x\n",
    "        return self.hash_fn(ndata['integrants'], prefix=prefix)\n",
    "\n",
    "    def find_by_hash(self, x, prefix=None) -> List[Tuple[Node, Dict]]:\n",
    "        k1 = self.hash_fn(x, prefix=prefix)\n",
    "        visited = []\n",
    "        for x in self.prov.nodes(data=True):\n",
    "\n",
    "            ndata = x[1]\n",
    "            if 'mating_type' in ndata:\n",
    "                k2 = self.node_to_hash_fn(x, prefix=ndata['mating_type'])\n",
    "                if k1 == k2:\n",
    "                    visited.append(x)\n",
    "        return visited\n",
    "\n",
    "    def hash_fn(self, x, prefix=None):\n",
    "        return HashFunctions.int_list_hash(x, prefix=prefix)\n",
    "\n",
    "    def build_prov_graph(self, strains: Optional[List[ModelBase]] = None, n=None) -> nx.DiGraph:\n",
    "        g = self._build_prov_graph(strains, n=n)\n",
    "        grev = g.reverse()\n",
    "        for n in grev.nodes():\n",
    "            integrants = list(self._get_integrants(n, grev))\n",
    "            g.nodes[n]['integrants'] = tuple(sorted(integrants))\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_integrants(n, grev):\n",
    "        for n1, n2 in list(nx.dfs_edges(grev, n)):\n",
    "            edata = grev[n1][n2]\n",
    "            if edata['field_name'] == 'Integrant':\n",
    "                yield n2\n",
    "\n",
    "    def _build_prov_graph(self, strains: Optional[List[ModelBase]] = None, n=None) -> nx.DiGraph:\n",
    "        g = nx.DiGraph()\n",
    "\n",
    "        def add_sample_node(s, **kwargs):\n",
    "            g.add_node(s.id, sample_type=s.sample_type_id, sample=s.dump(), **kwargs)\n",
    "\n",
    "        if not strains:\n",
    "            assert n\n",
    "            strains = self.sess.Sample.last(n, query={\n",
    "                'sample_type_id': self.common['sample_types']['yeast'].id,\n",
    "                'user_id': 66\n",
    "            })\n",
    "        while strains:\n",
    "            if strains:\n",
    "                self.sess.browser.get(strains, {\n",
    "                    'field_values': {\n",
    "                        'field_type': 'allowable_field_types',\n",
    "                        'sample': []\n",
    "                    },\n",
    "                    'sample_type': {\n",
    "                        'field_types': 'allowable_field_types'\n",
    "                    }\n",
    "                })\n",
    "\n",
    "                parents = {}\n",
    "                for s in strains:\n",
    "                    add_sample_node(s, mating_type=s.properties['Mating Type'])\n",
    "\n",
    "                    parent = None\n",
    "                    if 'Parent' in s.properties:\n",
    "                        parent = s.properties['Parent']\n",
    "\n",
    "                    integrant = None\n",
    "                    if 'Integrant' in s.properties:\n",
    "                        integrant = s.properties['Integrant']\n",
    "\n",
    "                    if parent is not None:\n",
    "                        parents[parent.id] = parent\n",
    "                        add_sample_node(parent, mating_type=parent.properties['Mating Type'])\n",
    "                        g.add_edge(parent.id, s.id, field_name='Parent')\n",
    "\n",
    "                    if integrant is not None:\n",
    "                        add_sample_node(integrant)\n",
    "                        g.add_edge(integrant.id, s.id, field_name='Integrant', sample=integrant.dump())\n",
    "\n",
    "            new_parents = {}\n",
    "            sids = [s.id for s in strains]\n",
    "            for sid, p in parents.items():\n",
    "                if sid not in sids:\n",
    "                    new_parents[sid] = p\n",
    "            strains = list(new_parents.values())\n",
    "        return g\n",
    "\n",
    "    def find_in_cache(self, query: dict, model_name: str):\n",
    "        visited = []\n",
    "        for item in self.sess.browser.model_cache[model_name].values():\n",
    "            for k, v in query.items():\n",
    "                if getattr(item, k) == v:\n",
    "                    visited.append(item)\n",
    "        return visited\n",
    "\n",
    "    def find_yeast_items(self, sample_id):\n",
    "        items = self.find_items(sample_id, [ot.id for ot in self.common['object_types']['yeast']])\n",
    "        return items\n",
    "\n",
    "    def find_dna_items(self, sample_id):\n",
    "        items = self.find_items(sample_id, [ot.id for ot in self.common['object_types']['dna']])\n",
    "        return items\n",
    "\n",
    "    def find_items(self, sample_id, otids):\n",
    "        visited = []\n",
    "        for item in self.sess.browser.model_cache[\"Item\"].values():\n",
    "            if item.sample_id == sample_id and item.location != 'deleted' and item.object_type_id in otids:\n",
    "                visited.append(item)\n",
    "        return visited\n",
    "\n",
    "    def cache_items(self):\n",
    "        all_ots = []\n",
    "        for k, v in self.common['object_types'].items():\n",
    "            all_ots.extend(v)\n",
    "        ot_by_st = {}\n",
    "        for ot in all_ots:\n",
    "            ot_by_st.setdefault(ot.sample_type_id, list())\n",
    "            ot_by_st[ot.sample_type_id].append(ot)\n",
    "\n",
    "        for stid, ots in ot_by_st.items():\n",
    "            samples = self.find_in_cache({'sample_type_id': stid}, 'Sample')\n",
    "            self._cache_items([s.id for s in samples], ots)\n",
    "\n",
    "    def _cache_items(self, sample_ids: List[int], object_types):\n",
    "        sess = self.sess\n",
    "        ots = get_models(sess, object_types, 'ObjectType')\n",
    "        items = []\n",
    "        for ot in self.progressbar(ots):\n",
    "            query = {'sample_id': sample_ids, 'object_type_id': ot.id}\n",
    "            items_ = sess.Item.where(query)\n",
    "            items_ = [i for i in items_ if i.location != 'deleted']\n",
    "            items.extend(items_)\n",
    "        return items\n",
    "\n",
    "    def create_trajectories(self, prefix, parts_arr, g=None) -> nx.DiGraph:\n",
    "        \"\"\"\n",
    "        Create all possible build trajectories.\n",
    "\n",
    "        :param prefix:\n",
    "        :param parts_arr:\n",
    "        :param g:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if g is None:\n",
    "            g = nx.DiGraph()\n",
    "        for parts_arr_ in parts_arr:\n",
    "            n1 = self.hash_fn(prefix, parts_arr_)\n",
    "            visited = []\n",
    "            for parts, x in iter_split_sets(parts_arr_):\n",
    "                if len(parts) > 1:\n",
    "                    visited.append(parts)\n",
    "                n2 = self.hash_fn(prefix, parts)\n",
    "                g.add_edge(n2, n1, plasmid_id=x)\n",
    "            self.create_trajectories(prefix, visited, g=g)\n",
    "        return g\n",
    "\n",
    "\n",
    "def by_key_value(arr, keyfn, valuefn, iffn=None):\n",
    "    data = {}\n",
    "    for a in arr:\n",
    "        key = keyfn(a)\n",
    "        data.setdefault(key, list())\n",
    "        v = valuefn(a)\n",
    "        if iffn and iffn(v):\n",
    "            data[key].append(valuefn(a))\n",
    "    return data\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class BuildPaths(object):\n",
    "\n",
    "    def __init__(self, db: LIMSDB):\n",
    "        self.db = db\n",
    "\n",
    "    def create_trajectories(self, prefix, parts_arr, g=None) -> nx.DiGraph:\n",
    "        \"\"\"\n",
    "        Create all possible build trajectories.\n",
    "\n",
    "        :param prefix:\n",
    "        :param parts_arr:\n",
    "        :param g:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        hash_fn = self.db.hash_fn\n",
    "        if g is None:\n",
    "            g = nx.DiGraph()\n",
    "        for parts_arr_ in parts_arr:\n",
    "            n1 = hash_fn(x=parts_arr_, prefix=prefix)\n",
    "            visited = []\n",
    "            for parts, x in iter_split_sets(parts_arr_):\n",
    "                if len(parts) > 1:\n",
    "                    visited.append(parts)\n",
    "                n2 = hash_fn(x=parts, prefix=prefix)\n",
    "                g.add_edge(n2, n1, plasmid_id=x)\n",
    "            self.create_trajectories(prefix, visited, g=g)\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_parts(parts):\n",
    "\n",
    "        for part in parts:\n",
    "            assert 'gate' in part\n",
    "            assert 'haploid' in part\n",
    "            assert 'sample' in part\n",
    "\n",
    "    def generate_build_paths(self, parts: List[dict]):\n",
    "        parts = deepcopy(parts)\n",
    "        for part in parts:\n",
    "            sample = self.db.sess.Sample.find_by_name(part['sample']['name'])\n",
    "            part['sample'] = sample.dump()\n",
    "        self.validate_parts(parts)\n",
    "        partsdict = by_key_value(parts, lambda x: x['haploid'], lambda x: x['sample']['id'], lambda x: True)\n",
    "        trajectories = {}\n",
    "        print(partsdict)\n",
    "        for haploid, parts in partsdict.items():\n",
    "            traj = self.create_trajectories(prefix=haploid, parts_arr=[parts])\n",
    "\n",
    "            nodelist = list(traj.nodes())\n",
    "            traj.add_node(\"START\")\n",
    "\n",
    "            for n1 in nodelist:\n",
    "                prefix, parts_ = n1\n",
    "                if prefix == 'Mat A':\n",
    "                    prefix = 'MATa'\n",
    "                elif prefix == 'Mat Alpha':\n",
    "                    prefix = 'MATalpha'\n",
    "                else:\n",
    "                    raise RuntimeError('prefix \"{}\" unexpected for {}'.format(prefix, n1))\n",
    "\n",
    "                found = self.db.find_by_hash(parts_, prefix=prefix)\n",
    "                for sample_id, ndata2 in found:\n",
    "                    items = self.db.find_yeast_items(sample_id)\n",
    "                    if items:\n",
    "                        traj.add_edge('START', n1, weight=0)\n",
    "\n",
    "            for n1, n2, edata in traj.edges(data=True):\n",
    "                if n1 != 'START':\n",
    "                    plasmid_id = edata['plasmid_id']\n",
    "                    items = self.db.find_dna_items(plasmid_id)\n",
    "                    if items:\n",
    "                        edata['weight'] = 1\n",
    "                    else:\n",
    "                        edata['weight'] = 4\n",
    "\n",
    "            trajectories[haploid] = traj\n",
    "        return trajectories\n",
    "\n",
    "\n",
    "def by_key_value(arr, keyfn, valuefn, iffn=None):\n",
    "    data = {}\n",
    "    for a in arr:\n",
    "        key = keyfn(a)\n",
    "        data.setdefault(key, list())\n",
    "        v = valuefn(a)\n",
    "        if iffn and iffn(v):\n",
    "            data[key].append(valuefn(a))\n",
    "    return data\n",
    "\n",
    "class BuildPaths(object):\n",
    "\n",
    "    def __init__(self, db: LIMSDB):\n",
    "        self.db = db\n",
    "\n",
    "    def create_trajectories(self, prefix, parts_arr, g=None) -> nx.DiGraph:\n",
    "        \"\"\"\n",
    "        Create all possible build trajectories.\n",
    "\n",
    "        :param prefix:\n",
    "        :param parts_arr:\n",
    "        :param g:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        hash_fn = self.db.hash_fn\n",
    "        if g is None:\n",
    "            g = nx.DiGraph()\n",
    "        for parts_arr_ in parts_arr:\n",
    "            n1 = hash_fn(x=parts_arr_, prefix=prefix)\n",
    "            visited = []\n",
    "            for parts, x in iter_split_sets(parts_arr_):\n",
    "                if len(parts) > 1:\n",
    "                    visited.append(parts)\n",
    "                n2 = hash_fn(x=parts, prefix=prefix)\n",
    "                g.add_edge(n2, n1, plasmid_id=x)\n",
    "            self.create_trajectories(prefix, visited, g=g)\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_parts(parts):\n",
    "\n",
    "        for part in parts:\n",
    "            assert 'gate' in part\n",
    "            assert 'haploid' in part\n",
    "            assert 'sample' in part\n",
    "\n",
    "\n",
    "\n",
    "    def generate_build_paths(self, parts: List[dict]):\n",
    "        parts = deepcopy(parts)\n",
    "        for part in parts:\n",
    "            sample = self.db.sess.Sample.find_by_name(part['sample']['name'])\n",
    "            part['sample'] = sample.dump()\n",
    "        self.validate_parts(parts)\n",
    "        partsdict = by_key_value(parts, lambda x: x['haploid'], lambda x: x['sample']['id'], lambda x: True)\n",
    "        trajectories = {}\n",
    "        print(partsdict)\n",
    "        for haploid, parts in partsdict.items():\n",
    "            traj = self.create_trajectories(prefix=haploid, parts_arr=[parts])\n",
    "\n",
    "            nodelist = list(traj.nodes())\n",
    "            traj.add_node(\"START\")\n",
    "\n",
    "            for n1 in nodelist:\n",
    "                prefix, parts_ = n1\n",
    "                if prefix == 'Mat A':\n",
    "                    prefix = 'MATa'\n",
    "                elif prefix == 'Mat Alpha':\n",
    "                    prefix = 'MATalpha'\n",
    "                else:\n",
    "                    raise RuntimeError('prefix \"{}\" unexpected for {}'.format(prefix, n1))\n",
    "\n",
    "                found = self.db.find_by_hash(parts_, prefix=prefix)\n",
    "                for sample_id, ndata2 in found:\n",
    "                    items = self.db.find_yeast_items(sample_id)\n",
    "                    if items:\n",
    "                        traj.add_edge('START', n1, weight=0)\n",
    "\n",
    "            for n1, n2, edata in traj.edges(data=True):\n",
    "                if n1 != 'START':\n",
    "                    plasmid_id = edata['plasmid_id']\n",
    "                    items = self.db.find_dna_items(plasmid_id)\n",
    "                    if items:\n",
    "                        edata['weight'] = 1\n",
    "                    else:\n",
    "                        edata['weight'] = 4\n",
    "\n",
    "            trajectories[haploid] = traj\n",
    "        return trajectories\n",
    "\n",
    "    def generate_instructions(self, parts):\n",
    "        self.validate_parts(parts)\n",
    "\n",
    "        instructions = []\n",
    "\n",
    "        for h, g in self.generate_build_paths(parts).items():\n",
    "            leaves = list(iter_leaves(g))\n",
    "            assert len(leaves) == 1\n",
    "            paths = list(nx.all_shortest_paths(g, 'START', leaves[0]))\n",
    "            path_weights = []\n",
    "            for path in paths:\n",
    "                weights = []\n",
    "                for n1, n2 in nx.utils.pairwise(path):\n",
    "                    weights.append(g[n1][n2]['weight'])\n",
    "                path_weights.append(tuple(weights))\n",
    "            sorted_paths = sorted(list(zip(paths, path_weights)), key=lambda x: x[1])\n",
    "            best_path = sorted_paths[0]\n",
    "            for i, (n1, n2) in enumerate(nx.utils.pairwise(best_path[0])):\n",
    "                if n1 == \"START\":\n",
    "                    continue\n",
    "                p1 = n1[0]\n",
    "                p2 = n2[0]\n",
    "                _prefix = {\n",
    "                    'Mat A': 'MATa',\n",
    "                    'Mat Alpha': 'MATalpha'\n",
    "                }\n",
    "                p1 = _prefix[p1]\n",
    "                p2 = _prefix[p2]\n",
    "\n",
    "                s1 = self.db.find_by_hash(list(n1[1]), prefix=p1)\n",
    "                s2 = self.db.find_by_hash(list(n2[1]), prefix=p2)\n",
    "                edata = g[n1][n2]\n",
    "\n",
    "                if s1:\n",
    "                    parent = [(_s[0], _s[1]['sample']['name']) for _s in s1]\n",
    "                else:\n",
    "                    parent = n1\n",
    "\n",
    "                if s2:\n",
    "                    result = [(_s[0], _s[1]['sample']['name']) for _s in s2]\n",
    "                else:\n",
    "                    result = n2\n",
    "\n",
    "                instructions.append({\n",
    "                    'step': i,\n",
    "                    'parent': parent,\n",
    "                    'dna': edata['plasmid_id'],\n",
    "                    'result': result,\n",
    "                    'weight': edata['weight']\n",
    "                })\n",
    "\n",
    "        return instructions\n",
    "\n",
    "    def parse_builds(self, builds):\n",
    "        all_rows = []\n",
    "        for build in builds:\n",
    "            parts = build['parts']\n",
    "            data = dict(build)\n",
    "            data['id'] = data['name'] + \"_\" + str(data['permutation'])\n",
    "            del data['parts']\n",
    "            rows = self.generate_instructions(parts)\n",
    "            for row in rows:\n",
    "                row.update(data)\n",
    "            all_rows.extend(rows)\n",
    "        return pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "competitive-medicine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c717d9b8ee4983a28bb86b1a2be4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73edf7eeade3431db09def216cd96824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2917a1148e491abf509037d638c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = LIMSDB(sess, n=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "informal-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mat A': [33579, 1380, 36332, 36333], 'Mat Alpha': [1096, 5533, 36334, 36335, 36336]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36334, 36335, 36336]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36338, 36335, 36336]}\n",
      "{'Mat A': [33579, 1380, 36339, 36340], 'Mat Alpha': [1096, 5534, 36341, 36342, 36343]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36341, 36342, 36343]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36345, 36342, 36343]}\n",
      "{'Mat A': [33579, 1380, 36332, 36333], 'Mat Alpha': [1096, 5533, 36346, 36347]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36346, 36347]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36348, 36347]}\n",
      "{'Mat A': [33579, 1380, 36339, 36349], 'Mat Alpha': [1096, 5534, 36344, 36350]}\n",
      "{'Mat A': [33579, 1380, 36339, 36351], 'Mat Alpha': [1096, 5534, 36344, 36350]}\n",
      "{'Mat A': [33579, 1380, 36339, 36351], 'Mat Alpha': [1096, 5534, 36352, 36350]}\n",
      "{'Mat A': [33579, 1380, 36353], 'Mat Alpha': [1096, 5537, 36354]}\n",
      "{'Mat A': [33579, 1380, 36353], 'Mat Alpha': [1096, 5537, 36354]}\n",
      "{'Mat A': [33579, 1380, 36353], 'Mat Alpha': [1096, 5537, 36354]}\n",
      "{'Mat A': [33579, 1380, 36339], 'Mat Alpha': [1096, 5536, 36355]}\n",
      "{'Mat A': [33579, 1380, 36339], 'Mat Alpha': [1096, 5536, 36355]}\n",
      "{'Mat A': [33579, 1380, 36339], 'Mat Alpha': [1096, 5536, 36355]}\n",
      "{'Mat A': [33579, 1380, 36332, 36356], 'Mat Alpha': [1096, 5535, 36357]}\n",
      "{'Mat A': [33579, 1380, 36332, 36358], 'Mat Alpha': [1096, 5535, 36357]}\n",
      "{'Mat A': [33579, 1380, 36332, 36358], 'Mat Alpha': [1096, 5535, 36357]}\n",
      "{'Mat A': [33579, 1380, 36339, 36340], 'Mat Alpha': [1096, 5534, 36359]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36359]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36359]}\n"
     ]
    }
   ],
   "source": [
    "buildpaths = BuildPaths(db)\n",
    "builddf = buildpaths.parse_builds(builds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "underlying-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "builddf.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "coordinate-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "builddf[builddf.permutation == 0].to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
