{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comic-values",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accessory-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.path.abspath('../..')\n",
    "if path not in sys.path:\n",
    "    sys.path.insert(0, path)\n",
    "    \n",
    "sys.path\n",
    "\n",
    "from primer3plus.utils import reverse_complement as rc\n",
    "import primer3\n",
    "from aqbt.contrib.uwbf import primer_utils\n",
    "from aqbt import AquariumBuildTools\n",
    "aqtools = AquariumBuildTools.from_toml('creds.secret.toml')\n",
    "aqtools.sessions\n",
    "\n",
    "aq = aqtools.sessions['production']['aquarium']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-gardening",
   "metadata": {},
   "source": [
    "## Potential Build Trajectories\n",
    "\n",
    "We create every possible build trajectory for a given goal build. Builds are defined as a sorted set of integrant ids to be found in the resulting strain. The sorted set of tuples is known as a **part_hash**. We create a DAG with node ids being a sorted tuple of integrant ids and between these nodes indicating a transformation; plasmid_ids can be found as attributes along the edges.\n",
    "\n",
    "*TODO* Weights will be determined by the availability of integrants\n",
    "*TODO* start node should be provided. If a strain exists, an edge from START to the node should added with `weight=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affecting-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = aq.with_cache(timeout=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifth-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import Hashable, Generator, TypeVar, List, Tuple, Optional, Dict, Callable\n",
    "from pydent import AqSession\n",
    "from pydent import ModelBase\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "Node = Hashable\n",
    "_T = TypeVar('_T')\n",
    "\n",
    "\n",
    "def is_leaf(n: Node, g: nx.DiGraph):\n",
    "    successors = list(g.successors(n))\n",
    "    if successors:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def is_root(n: Node, g: nx.DiGraph):\n",
    "    predecessors = list(g.predecessors(n))\n",
    "    if predecessors:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def iter_leaves(g: nx.DiGraph) -> Generator[Node, None, None]:\n",
    "    for n in g.nodes():\n",
    "        if is_leaf(n, g):\n",
    "            yield n\n",
    "\n",
    "\n",
    "def iter_roots(g: nx.DiGraph) -> Generator[Node, None, None]:\n",
    "    for n in g.nodes():\n",
    "        if is_root(n, g):\n",
    "            yield n\n",
    "\n",
    "\n",
    "def iter_split_sets(arr: List[_T]) -> Tuple[List[_T], _T]:\n",
    "    for i in range(len(arr)):\n",
    "        yield tuple(arr[:i] + arr[i + 1:]), arr[i]\n",
    "\n",
    "\n",
    "class HashFunctions(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def int_list_hash(ids: List[int], prefix: Optional[str] = None) -> Tuple[str, Tuple[int]]:\n",
    "        return prefix, tuple(sorted(ids))\n",
    "\n",
    "\n",
    "def group_by_sample_id(items):\n",
    "    data = {}\n",
    "    for item in items:\n",
    "        data.setdefault(item.sample_id, list())\n",
    "        data[item.sample_id].append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def group_by_object_type_id(items):\n",
    "    data = {}\n",
    "    for item in items:\n",
    "        data.setdefault(item.object_type_id, list())\n",
    "        data[item.object_type_id].append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def is_aq_model(x):\n",
    "    return issubclass(x.__class__, ModelBase)\n",
    "\n",
    "\n",
    "def get_models(sess, x, model):\n",
    "    interface = sess.model_interface(model)\n",
    "    if isinstance(x, int):\n",
    "        res = [interface.find(x)]\n",
    "        if res[0] is None:\n",
    "            raise ValueError(\"Could not find {}\".format(x))\n",
    "    elif isinstance(x, str):\n",
    "        res = [interface.find_by_name(x)]\n",
    "        if res[0] is None:\n",
    "            raise ValueError(\"Could not find {}\".format(x))\n",
    "    elif is_aq_model(x):\n",
    "        res = [x]\n",
    "        if res is None:\n",
    "            raise ValueError\n",
    "    elif isinstance(x, dict):\n",
    "        res = interface.where(x)\n",
    "        if res is None:\n",
    "            raise ValueError\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        res = []\n",
    "        for _x in x:\n",
    "            res.extend(get_models(sess, _x, model))\n",
    "    else:\n",
    "        raise TypeError\n",
    "    return res\n",
    "\n",
    "\n",
    "class LIMSDB(object):\n",
    "    YEAST_OBJECT_TYPES = ['Yeast Glycerol Stock', 'Yeast Plate', 'Yeast Competent Aliquot', 'Yeast Competent Cell']\n",
    "    DNA_OBJECT_TYPES = ['Plasmid Stock', 'Plasmid Glycerol Stock', '1 ng/µL Plasmid Stock', 'Fragment Stock',\n",
    "                        '1 ng/µL Fragment Stock']\n",
    "\n",
    "    def __init__(self, sess: AqSession, strains=None, n=None, timeout: int = 60, progressbar: Callable = tqdm):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sess:\n",
    "        :param strains:\n",
    "        :param n:\n",
    "        :param timeout:\n",
    "        :param progressbar:\n",
    "        \"\"\"\n",
    "        self.progressbar = progressbar\n",
    "        self.sess = sess.with_cache(timeout=timeout)\n",
    "        self.common = {\n",
    "            'sample_types': {\n",
    "                'yeast': self.sess.SampleType.find_by_name('Yeast Strain'),\n",
    "                'plasmid': self.sess.SampleType.find_by_name('Plasmid'),\n",
    "                'fragment': self.sess.SampleType.find_by_name('Fragment'),\n",
    "            },\n",
    "            'object_types': {\n",
    "                'yeast': get_models(self.sess, self.YEAST_OBJECT_TYPES, 'ObjectType'),\n",
    "                'dna': get_models(self.sess, self.DNA_OBJECT_TYPES, 'ObjectType')\n",
    "            }\n",
    "        }\n",
    "        self.prov: nx.DiGraph = self.build_prov_graph(strains=strains, n=n)\n",
    "        self.cache_items()\n",
    "\n",
    "    def node_to_hash_fn(self, x, prefix=None):\n",
    "        node, ndata = x\n",
    "        return self.hash_fn(ndata['integrants'], prefix=prefix)\n",
    "\n",
    "    def find_by_hash(self, x, prefix=None) -> List[Tuple[Node, Dict]]:\n",
    "        k1 = self.hash_fn(x, prefix=prefix)\n",
    "        visited = []\n",
    "        for x in self.prov.nodes(data=True):\n",
    "\n",
    "            ndata = x[1]\n",
    "            if 'mating_type' in ndata:\n",
    "                k2 = self.node_to_hash_fn(x, prefix=ndata['mating_type'])\n",
    "                if k1 == k2:\n",
    "                    visited.append(x)\n",
    "        return visited\n",
    "\n",
    "    def hash_fn(self, x, prefix=None):\n",
    "        return HashFunctions.int_list_hash(x, prefix=prefix)\n",
    "\n",
    "    def build_prov_graph(self, strains: Optional[List[ModelBase]] = None, n=None) -> nx.DiGraph:\n",
    "        g = self._build_prov_graph(strains, n=n)\n",
    "        grev = g.reverse()\n",
    "        for n in grev.nodes():\n",
    "            integrants = list(self._get_integrants(n, grev))\n",
    "            g.nodes[n]['integrants'] = tuple(sorted(integrants))\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_integrants(n, grev):\n",
    "        for n1, n2 in list(nx.dfs_edges(grev, n)):\n",
    "            edata = grev[n1][n2]\n",
    "            if edata['field_name'] == 'Integrant':\n",
    "                yield n2\n",
    "\n",
    "    def _build_prov_graph(self, strains: Optional[List[ModelBase]] = None, n=None) -> nx.DiGraph:\n",
    "        g = nx.DiGraph()\n",
    "\n",
    "        def add_sample_node(s, **kwargs):\n",
    "            g.add_node(s.id, sample_type=s.sample_type_id, sample=s.dump(), **kwargs)\n",
    "\n",
    "        if not strains:\n",
    "            assert n\n",
    "            strains = self.sess.Sample.last(n, query={\n",
    "                'sample_type_id': self.common['sample_types']['yeast'].id,\n",
    "                'user_id': 66\n",
    "            })\n",
    "        while strains:\n",
    "            if strains:\n",
    "                self.sess.browser.get(strains, {\n",
    "                    'field_values': {\n",
    "                        'field_type': 'allowable_field_types',\n",
    "                        'sample': []\n",
    "                    },\n",
    "                    'sample_type': {\n",
    "                        'field_types': 'allowable_field_types'\n",
    "                    }\n",
    "                })\n",
    "\n",
    "                parents = {}\n",
    "                for s in strains:\n",
    "                    add_sample_node(s, mating_type=s.properties['Mating Type'])\n",
    "\n",
    "                    parent = None\n",
    "                    if 'Parent' in s.properties:\n",
    "                        parent = s.properties['Parent']\n",
    "\n",
    "                    integrant = None\n",
    "                    if 'Integrant' in s.properties:\n",
    "                        integrant = s.properties['Integrant']\n",
    "\n",
    "                    if parent is not None:\n",
    "                        parents[parent.id] = parent\n",
    "                        add_sample_node(parent, mating_type=parent.properties['Mating Type'])\n",
    "                        g.add_edge(parent.id, s.id, field_name='Parent')\n",
    "\n",
    "                    if integrant is not None:\n",
    "                        add_sample_node(integrant)\n",
    "                        g.add_edge(integrant.id, s.id, field_name='Integrant', sample=integrant.dump())\n",
    "\n",
    "            new_parents = {}\n",
    "            sids = [s.id for s in strains]\n",
    "            for sid, p in parents.items():\n",
    "                if sid not in sids:\n",
    "                    new_parents[sid] = p\n",
    "            strains = list(new_parents.values())\n",
    "        return g\n",
    "\n",
    "    def find_in_cache(self, query: dict, model_name: str):\n",
    "        visited = []\n",
    "        for item in self.sess.browser.model_cache[model_name].values():\n",
    "            for k, v in query.items():\n",
    "                if getattr(item, k) == v:\n",
    "                    visited.append(item)\n",
    "        return visited\n",
    "\n",
    "    def find_yeast_items(self, sample_id):\n",
    "        items = self.find_items(sample_id, [ot.id for ot in self.common['object_types']['yeast']])\n",
    "        return items\n",
    "\n",
    "    def find_dna_items(self, sample_id):\n",
    "        items = self.find_items(sample_id, [ot.id for ot in self.common['object_types']['dna']])\n",
    "        return items\n",
    "\n",
    "    def find_items(self, sample_id, otids):\n",
    "        visited = []\n",
    "        for item in self.sess.browser.model_cache[\"Item\"].values():\n",
    "            if item.sample_id == sample_id and item.location != 'deleted' and item.object_type_id in otids:\n",
    "                visited.append(item)\n",
    "        return visited\n",
    "\n",
    "    def cache_items(self):\n",
    "        all_ots = []\n",
    "        for k, v in self.common['object_types'].items():\n",
    "            all_ots.extend(v)\n",
    "        ot_by_st = {}\n",
    "        for ot in all_ots:\n",
    "            ot_by_st.setdefault(ot.sample_type_id, list())\n",
    "            ot_by_st[ot.sample_type_id].append(ot)\n",
    "\n",
    "        for stid, ots in ot_by_st.items():\n",
    "            samples = self.find_in_cache({'sample_type_id': stid}, 'Sample')\n",
    "            self._cache_items([s.id for s in samples], ots)\n",
    "\n",
    "    def _cache_items(self, sample_ids: List[int], object_types):\n",
    "        sess = self.sess\n",
    "        ots = get_models(sess, object_types, 'ObjectType')\n",
    "        items = []\n",
    "        for ot in self.progressbar(ots):\n",
    "            query = {'sample_id': sample_ids, 'object_type_id': ot.id}\n",
    "            items_ = sess.Item.where(query)\n",
    "            items_ = [i for i in items_ if i.location != 'deleted']\n",
    "            items.extend(items_)\n",
    "        return items\n",
    "\n",
    "    def create_trajectories(self, prefix, parts_arr, g=None) -> nx.DiGraph:\n",
    "        \"\"\"\n",
    "        Create all possible build trajectories.\n",
    "\n",
    "        :param prefix:\n",
    "        :param parts_arr:\n",
    "        :param g:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if g is None:\n",
    "            g = nx.DiGraph()\n",
    "        for parts_arr_ in parts_arr:\n",
    "            n1 = self.hash_fn(prefix, parts_arr_)\n",
    "            visited = []\n",
    "            for parts, x in iter_split_sets(parts_arr_):\n",
    "                if len(parts) > 1:\n",
    "                    visited.append(parts)\n",
    "                n2 = self.hash_fn(prefix, parts)\n",
    "                g.add_edge(n2, n1, plasmid_id=x)\n",
    "            self.create_trajectories(prefix, visited, g=g)\n",
    "        return g\n",
    "\n",
    "\n",
    "def by_key_value(arr, keyfn, valuefn, iffn=None):\n",
    "    data = {}\n",
    "    for a in arr:\n",
    "        key = keyfn(a)\n",
    "        data.setdefault(key, list())\n",
    "        v = valuefn(a)\n",
    "        if iffn and iffn(v):\n",
    "            data[key].append(valuefn(a))\n",
    "    return data\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class BuildPaths(object):\n",
    "\n",
    "    def __init__(self, db: LIMSDB):\n",
    "        self.db = db\n",
    "\n",
    "    def create_trajectories(self, prefix, parts_arr, g=None) -> nx.DiGraph:\n",
    "        \"\"\"\n",
    "        Create all possible build trajectories.\n",
    "\n",
    "        :param prefix:\n",
    "        :param parts_arr:\n",
    "        :param g:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        hash_fn = self.db.hash_fn\n",
    "        if g is None:\n",
    "            g = nx.DiGraph()\n",
    "        for parts_arr_ in parts_arr:\n",
    "            n1 = hash_fn(x=parts_arr_, prefix=prefix)\n",
    "            visited = []\n",
    "            for parts, x in iter_split_sets(parts_arr_):\n",
    "                if len(parts) > 1:\n",
    "                    visited.append(parts)\n",
    "                n2 = hash_fn(x=parts, prefix=prefix)\n",
    "                g.add_edge(n2, n1, plasmid_id=x)\n",
    "            self.create_trajectories(prefix, visited, g=g)\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_parts(parts):\n",
    "\n",
    "        for part in parts:\n",
    "            assert 'gate' in part\n",
    "            assert 'haploid' in part\n",
    "            assert 'sample' in part\n",
    "\n",
    "    def generate_build_paths(self, parts: List[dict]):\n",
    "        parts = deepcopy(parts)\n",
    "        for part in parts:\n",
    "            sample = self.db.sess.Sample.find_by_name(part['sample']['name'])\n",
    "            part['sample'] = sample.dump()\n",
    "        self.validate_parts(parts)\n",
    "        partsdict = by_key_value(parts, lambda x: x['haploid'], lambda x: x['sample']['id'], lambda x: True)\n",
    "        trajectories = {}\n",
    "        print(partsdict)\n",
    "        for haploid, parts in partsdict.items():\n",
    "            traj = self.create_trajectories(prefix=haploid, parts_arr=[parts])\n",
    "\n",
    "            nodelist = list(traj.nodes())\n",
    "            traj.add_node(\"START\")\n",
    "\n",
    "            for n1 in nodelist:\n",
    "                prefix, parts_ = n1\n",
    "                if prefix == 'Mat A':\n",
    "                    prefix = 'MATa'\n",
    "                elif prefix == 'Mat Alpha':\n",
    "                    prefix = 'MATalpha'\n",
    "                else:\n",
    "                    raise RuntimeError('prefix \"{}\" unexpected for {}'.format(prefix, n1))\n",
    "\n",
    "                found = self.db.find_by_hash(parts_, prefix=prefix)\n",
    "                for sample_id, ndata2 in found:\n",
    "                    items = self.db.find_yeast_items(sample_id)\n",
    "                    if items:\n",
    "                        traj.add_edge('START', n1, weight=0)\n",
    "\n",
    "            for n1, n2, edata in traj.edges(data=True):\n",
    "                if n1 != 'START':\n",
    "                    plasmid_id = edata['plasmid_id']\n",
    "                    items = self.db.find_dna_items(plasmid_id)\n",
    "                    if items:\n",
    "                        edata['weight'] = 1\n",
    "                    else:\n",
    "                        edata['weight'] = 4\n",
    "\n",
    "            trajectories[haploid] = traj\n",
    "        return trajectories\n",
    "\n",
    "\n",
    "def by_key_value(arr, keyfn, valuefn, iffn=None):\n",
    "    data = {}\n",
    "    for a in arr:\n",
    "        key = keyfn(a)\n",
    "        data.setdefault(key, list())\n",
    "        v = valuefn(a)\n",
    "        if iffn and iffn(v):\n",
    "            data[key].append(valuefn(a))\n",
    "    return data\n",
    "\n",
    "class BuildPaths(object):\n",
    "\n",
    "    def __init__(self, db: LIMSDB):\n",
    "        self.db = db\n",
    "\n",
    "    def create_trajectories(self, prefix, parts_arr, g=None) -> nx.DiGraph:\n",
    "        \"\"\"\n",
    "        Create all possible build trajectories.\n",
    "\n",
    "        :param prefix:\n",
    "        :param parts_arr:\n",
    "        :param g:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        hash_fn = self.db.hash_fn\n",
    "        if g is None:\n",
    "            g = nx.DiGraph()\n",
    "        for parts_arr_ in parts_arr:\n",
    "            n1 = hash_fn(x=parts_arr_, prefix=prefix)\n",
    "            visited = []\n",
    "            for parts, x in iter_split_sets(parts_arr_):\n",
    "                if len(parts) > 1:\n",
    "                    visited.append(parts)\n",
    "                n2 = hash_fn(x=parts, prefix=prefix)\n",
    "                g.add_edge(n2, n1, plasmid_id=x)\n",
    "            self.create_trajectories(prefix, visited, g=g)\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_parts(parts):\n",
    "\n",
    "        for part in parts:\n",
    "            assert 'gate' in part\n",
    "            assert 'haploid' in part\n",
    "            assert 'sample' in part\n",
    "\n",
    "\n",
    "\n",
    "    def generate_build_paths(self, parts: List[dict]):\n",
    "        parts = deepcopy(parts)\n",
    "        for part in parts:\n",
    "            sample = self.db.sess.Sample.find_by_name(part['sample']['name'])\n",
    "            part['sample'] = sample.dump()\n",
    "        self.validate_parts(parts)\n",
    "        partsdict = by_key_value(parts, lambda x: x['haploid'], lambda x: x['sample']['id'], lambda x: True)\n",
    "        trajectories = {}\n",
    "        print(partsdict)\n",
    "        for haploid, parts in partsdict.items():\n",
    "            traj = self.create_trajectories(prefix=haploid, parts_arr=[parts])\n",
    "\n",
    "            nodelist = list(traj.nodes())\n",
    "            traj.add_node(\"START\")\n",
    "\n",
    "            for n1 in nodelist:\n",
    "                prefix, parts_ = n1\n",
    "                if prefix == 'Mat A':\n",
    "                    prefix = 'MATa'\n",
    "                elif prefix == 'Mat Alpha':\n",
    "                    prefix = 'MATalpha'\n",
    "                else:\n",
    "                    raise RuntimeError('prefix \"{}\" unexpected for {}'.format(prefix, n1))\n",
    "\n",
    "                found = self.db.find_by_hash(parts_, prefix=prefix)\n",
    "                for sample_id, ndata2 in found:\n",
    "                    items = self.db.find_yeast_items(sample_id)\n",
    "                    if items:\n",
    "                        traj.add_edge('START', n1, weight=0)\n",
    "\n",
    "            for n1, n2, edata in traj.edges(data=True):\n",
    "                if n1 != 'START':\n",
    "                    plasmid_id = edata['plasmid_id']\n",
    "                    items = self.db.find_dna_items(plasmid_id)\n",
    "                    if items:\n",
    "                        edata['weight'] = 1\n",
    "                    else:\n",
    "                        edata['weight'] = 4\n",
    "\n",
    "            trajectories[haploid] = traj\n",
    "        return trajectories\n",
    "\n",
    "    def generate_instructions(self, parts):\n",
    "        self.validate_parts(parts)\n",
    "\n",
    "        instructions = []\n",
    "\n",
    "        for h, g in self.generate_build_paths(parts).items():\n",
    "            leaves = list(iter_leaves(g))\n",
    "            assert len(leaves) == 1\n",
    "            paths = list(nx.all_shortest_paths(g, 'START', leaves[0]))\n",
    "            path_weights = []\n",
    "            for path in paths:\n",
    "                weights = []\n",
    "                for n1, n2 in nx.utils.pairwise(path):\n",
    "                    weights.append(g[n1][n2]['weight'])\n",
    "                path_weights.append(tuple(weights))\n",
    "            sorted_paths = sorted(list(zip(paths, path_weights)), key=lambda x: x[1])\n",
    "            best_path = sorted_paths[0]\n",
    "            for i, (n1, n2) in enumerate(nx.utils.pairwise(best_path[0])):\n",
    "                if n1 == \"START\":\n",
    "                    continue\n",
    "                p1 = n1[0]\n",
    "                p2 = n2[0]\n",
    "                _prefix = {\n",
    "                    'Mat A': 'MATa',\n",
    "                    'Mat Alpha': 'MATalpha'\n",
    "                }\n",
    "                p1 = _prefix[p1]\n",
    "                p2 = _prefix[p2]\n",
    "\n",
    "                s1 = self.db.find_by_hash(list(n1[1]), prefix=p1)\n",
    "                s2 = self.db.find_by_hash(list(n2[1]), prefix=p2)\n",
    "                edata = g[n1][n2]\n",
    "\n",
    "                if s1:\n",
    "                    parent = [(_s[0], _s[1]['sample']['name']) for _s in s1]\n",
    "                else:\n",
    "                    parent = n1\n",
    "\n",
    "                if s2:\n",
    "                    result = [(_s[0], _s[1]['sample']['name']) for _s in s2]\n",
    "                else:\n",
    "                    result = n2\n",
    "\n",
    "                instructions.append({\n",
    "                    'step': i,\n",
    "                    'parent': parent,\n",
    "                    'dna': edata['plasmid_id'],\n",
    "                    'result': result,\n",
    "                    'weight': edata['weight']\n",
    "                })\n",
    "\n",
    "        return instructions\n",
    "\n",
    "    def parse_builds(self, builds):\n",
    "        all_rows = []\n",
    "        for build in builds:\n",
    "            parts = build['parts']\n",
    "            data = dict(build)\n",
    "            data['id'] = data['name'] + \"_\" + str(data['permutation'])\n",
    "            del data['parts']\n",
    "            rows = self.generate_instructions(parts)\n",
    "            for row in rows:\n",
    "                row.update(data)\n",
    "            all_rows.extend(rows)\n",
    "        return pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-worth",
   "metadata": {},
   "source": [
    "## Generate LIMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "korean-tooth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fb97e829d64c239e55d908853188f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7d0b1877f043fe8ebb320c222535a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d416fc6b34f04f0e9630d5d2b47d260c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = LIMSDB(sess, n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-turtle",
   "metadata": {},
   "source": [
    "### Generate Build Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moral-pastor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mat A': [33579, 1380, 36332, 36333], 'Mat Alpha': [1096, 5533, 36334, 36335, 36336]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36334, 36335, 36336]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36338, 36335, 36336]}\n",
      "{'Mat A': [33579, 1380, 36339, 36340], 'Mat Alpha': [1096, 5534, 36341, 36342, 36343]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36341, 36342, 36343]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36345, 36342, 36343]}\n",
      "{'Mat A': [33579, 1380, 36332, 36333], 'Mat Alpha': [1096, 5533, 36346, 36347]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36346, 36347]}\n",
      "{'Mat A': [33579, 1380, 36332, 36337], 'Mat Alpha': [1096, 5533, 36348, 36347]}\n",
      "{'Mat A': [33579, 1380, 36339, 36349], 'Mat Alpha': [1096, 5534, 36344, 36350]}\n",
      "{'Mat A': [33579, 1380, 36339, 36351], 'Mat Alpha': [1096, 5534, 36344, 36350]}\n",
      "{'Mat A': [33579, 1380, 36339, 36351], 'Mat Alpha': [1096, 5534, 36352, 36350]}\n",
      "{'Mat A': [33579, 1380, 36353], 'Mat Alpha': [1096, 5537, 36354]}\n",
      "{'Mat A': [33579, 1380, 36353], 'Mat Alpha': [1096, 5537, 36354]}\n",
      "{'Mat A': [33579, 1380, 36353], 'Mat Alpha': [1096, 5537, 36354]}\n",
      "{'Mat A': [33579, 1380, 36339], 'Mat Alpha': [1096, 5536, 36355]}\n",
      "{'Mat A': [33579, 1380, 36339], 'Mat Alpha': [1096, 5536, 36355]}\n",
      "{'Mat A': [33579, 1380, 36339], 'Mat Alpha': [1096, 5536, 36355]}\n",
      "{'Mat A': [33579, 1380, 36332, 36356], 'Mat Alpha': [1096, 5535, 36357]}\n",
      "{'Mat A': [33579, 1380, 36332, 36358], 'Mat Alpha': [1096, 5535, 36357]}\n",
      "{'Mat A': [33579, 1380, 36332, 36358], 'Mat Alpha': [1096, 5535, 36357]}\n",
      "{'Mat A': [33579, 1380, 36339, 36340], 'Mat Alpha': [1096, 5534, 36359]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36359]}\n",
      "{'Mat A': [33579, 1380, 36339, 36344], 'Mat Alpha': [1096, 5534, 36359]}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open('build_permutations_2021-03-08T10:16:09.773080-08:00_corrected.json', 'r') as f:\n",
    "    builds = json.load(f)\n",
    "\n",
    "buildpaths = BuildPaths(db)\n",
    "builddf = buildpaths.parse_builds(builds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "accredited-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builddf.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-darkness",
   "metadata": {},
   "source": [
    "### Display Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dutch-poland",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-8a60a5055ea1>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['dna_name'] = [aq.Sample.find(x).name for x in df.dna]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>parent</th>\n",
       "      <th>dna</th>\n",
       "      <th>result</th>\n",
       "      <th>weight</th>\n",
       "      <th>name</th>\n",
       "      <th>permutation</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>dna_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36332</td>\n",
       "      <td>[(36398, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>DSGRN NOR (BAD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN NOR (BAD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[(24943, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>36336</td>\n",
       "      <td>(Mat Alpha, (1096, 5533, 36336))</td>\n",
       "      <td>4</td>\n",
       "      <td>DSGRN NOR (BAD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN NOR (BAD)_0</td>\n",
       "      <td>URA-URA&lt;pGRR-W20W36-yeGFP&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36339</td>\n",
       "      <td>[(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>DSGRN NOR (GOOD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN NOR (GOOD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W34&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>[(24942, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>36343</td>\n",
       "      <td>(Mat Alpha, (1096, 5534, 36343))</td>\n",
       "      <td>4</td>\n",
       "      <td>DSGRN NOR (GOOD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN NOR (GOOD)_0</td>\n",
       "      <td>URA-URA&lt;pGRR-W10W20-yeGFP&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36332</td>\n",
       "      <td>[(36398, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>DSGRN OR (BAD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN OR (BAD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>[(24943, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>36347</td>\n",
       "      <td>[(36379, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>1</td>\n",
       "      <td>DSGRN OR (BAD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN OR (BAD)_0</td>\n",
       "      <td>URA-URA&lt;pGRR-W5W36-yeGFP&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36339</td>\n",
       "      <td>[(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>DSGRN OR (GOOD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN OR (GOOD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W34&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>[(24942, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>36350</td>\n",
       "      <td>(Mat Alpha, (1096, 5534, 36350))</td>\n",
       "      <td>4</td>\n",
       "      <td>DSGRN OR (GOOD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>DSGRN OR (GOOD)_0</td>\n",
       "      <td>URA-URA&lt;pGRR-W10W17-yeGFP&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36353</td>\n",
       "      <td>[(36396, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>GANDER NOR (BAD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>GANDER NOR (BAD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W5&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36339</td>\n",
       "      <td>[(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>GANDER NOR (GOOD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>GANDER NOR (GOOD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W34&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36332</td>\n",
       "      <td>[(36398, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>GANDER OR (BAD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>GANDER OR (BAD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>[(24940, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>36357</td>\n",
       "      <td>[(36383, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>1</td>\n",
       "      <td>GANDER OR (BAD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>GANDER OR (BAD)_0</td>\n",
       "      <td>URA-URA&lt;pGRR-W36W36-yeGFP&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>[(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>36339</td>\n",
       "      <td>[(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...</td>\n",
       "      <td>1</td>\n",
       "      <td>GANDER OR (GOOD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>GANDER OR (GOOD)_0</td>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W34&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>[(24942, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>36359</td>\n",
       "      <td>[(36380, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...</td>\n",
       "      <td>1</td>\n",
       "      <td>GANDER OR (GOOD)</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-08T09:30:22.723934-08:00</td>\n",
       "      <td>GANDER OR (GOOD)_0</td>\n",
       "      <td>URA-URA&lt;pGRR-W17W17-yeGFP&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step                                             parent    dna  \\\n",
       "0      1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36332   \n",
       "2      1  [(24943, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...  36336   \n",
       "15     1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36339   \n",
       "17     1  [(24942, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...  36343   \n",
       "30     1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36332   \n",
       "32     1  [(24943, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...  36347   \n",
       "42     1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36339   \n",
       "44     1  [(24942, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...  36350   \n",
       "54     1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36353   \n",
       "57     1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36339   \n",
       "60     1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36332   \n",
       "62     1  [(24940, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...  36357   \n",
       "69     1  [(33811, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...  36339   \n",
       "71     1  [(24942, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...  36359   \n",
       "\n",
       "                                               result  weight  \\\n",
       "0   [(36398, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "2                    (Mat Alpha, (1096, 5533, 36336))       4   \n",
       "15  [(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "17                   (Mat Alpha, (1096, 5534, 36343))       4   \n",
       "30  [(36398, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "32  [(36379, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...       1   \n",
       "42  [(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "44                   (Mat Alpha, (1096, 5534, 36350))       4   \n",
       "54  [(36396, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "57  [(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "60  [(36398, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "62  [(36383, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...       1   \n",
       "69  [(36397, CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1...       1   \n",
       "71  [(36380, CEN.PK2 - MAT alpha ::: pMODKan-HO-pA...       1   \n",
       "\n",
       "                 name  permutation                        created_at  \\\n",
       "0     DSGRN NOR (BAD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "2     DSGRN NOR (BAD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "15   DSGRN NOR (GOOD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "17   DSGRN NOR (GOOD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "30     DSGRN OR (BAD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "32     DSGRN OR (BAD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "42    DSGRN OR (GOOD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "44    DSGRN OR (GOOD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "54   GANDER NOR (BAD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "57  GANDER NOR (GOOD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "60    GANDER OR (BAD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "62    GANDER OR (BAD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "69   GANDER OR (GOOD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "71   GANDER OR (GOOD)            0  2021-03-08T09:30:22.723934-08:00   \n",
       "\n",
       "                     id                           dna_name  \n",
       "0     DSGRN NOR (BAD)_0   HIS-HIS<7XTetO-pMinCyc1-URGR-W8>  \n",
       "2     DSGRN NOR (BAD)_0         URA-URA<pGRR-W20W36-yeGFP>  \n",
       "15   DSGRN NOR (GOOD)_0  HIS-HIS<7XTetO-pMinCyc1-URGR-W34>  \n",
       "17   DSGRN NOR (GOOD)_0         URA-URA<pGRR-W10W20-yeGFP>  \n",
       "30     DSGRN OR (BAD)_0   HIS-HIS<7XTetO-pMinCyc1-URGR-W8>  \n",
       "32     DSGRN OR (BAD)_0          URA-URA<pGRR-W5W36-yeGFP>  \n",
       "42    DSGRN OR (GOOD)_0  HIS-HIS<7XTetO-pMinCyc1-URGR-W34>  \n",
       "44    DSGRN OR (GOOD)_0         URA-URA<pGRR-W10W17-yeGFP>  \n",
       "54   GANDER NOR (BAD)_0   HIS-HIS<7XTetO-pMinCyc1-URGR-W5>  \n",
       "57  GANDER NOR (GOOD)_0  HIS-HIS<7XTetO-pMinCyc1-URGR-W34>  \n",
       "60    GANDER OR (BAD)_0   HIS-HIS<7XTetO-pMinCyc1-URGR-W8>  \n",
       "62    GANDER OR (BAD)_0         URA-URA<pGRR-W36W36-yeGFP>  \n",
       "69   GANDER OR (GOOD)_0  HIS-HIS<7XTetO-pMinCyc1-URGR-W34>  \n",
       "71   GANDER OR (GOOD)_0         URA-URA<pGRR-W17W17-yeGFP>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformations: 14\n",
      "Fragment Usage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{36332: 3,\n",
       " 36336: 1,\n",
       " 36339: 4,\n",
       " 36343: 1,\n",
       " 36347: 1,\n",
       " 36350: 1,\n",
       " 36353: 1,\n",
       " 36357: 1,\n",
       " 36359: 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragment Locations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>type</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W8&gt;</td>\n",
       "      <td>36332</td>\n",
       "      <td>512002</td>\n",
       "      <td>1 ng/µL Fragment Stock</td>\n",
       "      <td>M20.24.1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URA-URA&lt;pGRR-W20W36-yeGFP&gt;</td>\n",
       "      <td>36336</td>\n",
       "      <td>no item</td>\n",
       "      <td>None</td>\n",
       "      <td>no item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W34&gt;</td>\n",
       "      <td>36339</td>\n",
       "      <td>511753</td>\n",
       "      <td>1 ng/µL Fragment Stock</td>\n",
       "      <td>M20.23.12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URA-URA&lt;pGRR-W10W20-yeGFP&gt;</td>\n",
       "      <td>36343</td>\n",
       "      <td>no item</td>\n",
       "      <td>None</td>\n",
       "      <td>no item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URA-URA&lt;pGRR-W5W36-yeGFP&gt;</td>\n",
       "      <td>36347</td>\n",
       "      <td>512004</td>\n",
       "      <td>1 ng/µL Fragment Stock</td>\n",
       "      <td>M20.24.1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>URA-URA&lt;pGRR-W10W17-yeGFP&gt;</td>\n",
       "      <td>36350</td>\n",
       "      <td>no item</td>\n",
       "      <td>None</td>\n",
       "      <td>no item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HIS-HIS&lt;7XTetO-pMinCyc1-URGR-W5&gt;</td>\n",
       "      <td>36353</td>\n",
       "      <td>511754</td>\n",
       "      <td>1 ng/µL Fragment Stock</td>\n",
       "      <td>M20.23.12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>URA-URA&lt;pGRR-W36W36-yeGFP&gt;</td>\n",
       "      <td>36357</td>\n",
       "      <td>512402</td>\n",
       "      <td>1 ng/µL Fragment Stock</td>\n",
       "      <td>M20.24.1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>URA-URA&lt;pGRR-W17W17-yeGFP&gt;</td>\n",
       "      <td>36359</td>\n",
       "      <td>512003</td>\n",
       "      <td>1 ng/µL Fragment Stock</td>\n",
       "      <td>M20.24.1.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sample_name  sample_id  item_id  \\\n",
       "0   HIS-HIS<7XTetO-pMinCyc1-URGR-W8>      36332   512002   \n",
       "1         URA-URA<pGRR-W20W36-yeGFP>      36336  no item   \n",
       "2  HIS-HIS<7XTetO-pMinCyc1-URGR-W34>      36339   511753   \n",
       "3         URA-URA<pGRR-W10W20-yeGFP>      36343  no item   \n",
       "4          URA-URA<pGRR-W5W36-yeGFP>      36347   512004   \n",
       "5         URA-URA<pGRR-W10W17-yeGFP>      36350  no item   \n",
       "6   HIS-HIS<7XTetO-pMinCyc1-URGR-W5>      36353   511754   \n",
       "7         URA-URA<pGRR-W36W36-yeGFP>      36357   512402   \n",
       "8         URA-URA<pGRR-W17W17-yeGFP>      36359   512003   \n",
       "\n",
       "                     type     location  \n",
       "0  1 ng/µL Fragment Stock  M20.24.1.40  \n",
       "1                    None      no item  \n",
       "2  1 ng/µL Fragment Stock  M20.23.12.2  \n",
       "3                    None      no item  \n",
       "4  1 ng/µL Fragment Stock  M20.24.1.42  \n",
       "5                    None      no item  \n",
       "6  1 ng/µL Fragment Stock  M20.23.12.5  \n",
       "7  1 ng/µL Fragment Stock  M20.24.1.32  \n",
       "8  1 ng/µL Fragment Stock  M20.24.1.41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeast Usage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{33811: 8, 24943: 2, 24942: 3, 24940: 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeast Locations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>type</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>451322</td>\n",
       "      <td>Yeast Glycerol Stock</td>\n",
       "      <td>M80.7.8.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>449991</td>\n",
       "      <td>Yeast Plate</td>\n",
       "      <td>DFP.6.3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>451421</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.2.15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>451422</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.2.15.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>451423</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.2.15.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>512162</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.3.0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>512163</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.3.0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...</td>\n",
       "      <td>33811</td>\n",
       "      <td>512164</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.3.1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...</td>\n",
       "      <td>24943</td>\n",
       "      <td>153612</td>\n",
       "      <td>Yeast Glycerol Stock</td>\n",
       "      <td>M80.5.8.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...</td>\n",
       "      <td>24943</td>\n",
       "      <td>315706</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.0.2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...</td>\n",
       "      <td>24942</td>\n",
       "      <td>153611</td>\n",
       "      <td>Yeast Glycerol Stock</td>\n",
       "      <td>M80.5.8.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...</td>\n",
       "      <td>24942</td>\n",
       "      <td>316029</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.2.2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...</td>\n",
       "      <td>24940</td>\n",
       "      <td>153400</td>\n",
       "      <td>Yeast Glycerol Stock</td>\n",
       "      <td>M80.5.8.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...</td>\n",
       "      <td>24940</td>\n",
       "      <td>512365</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.3.3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...</td>\n",
       "      <td>24940</td>\n",
       "      <td>512366</td>\n",
       "      <td>Yeast Competent Cell</td>\n",
       "      <td>M80C.3.3.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sample_name  sample_id  item_id  \\\n",
       "0   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   451322   \n",
       "1   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   449991   \n",
       "2   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   451421   \n",
       "3   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   451422   \n",
       "4   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   451423   \n",
       "5   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   512162   \n",
       "6   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   512163   \n",
       "7   CEN.PK2 - MAT A ::: pMOD4G-dcas9-mxi1 | pMOD-H...      33811   512164   \n",
       "8   CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...      24943   153612   \n",
       "9   CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...      24943   315706   \n",
       "10  CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...      24942   153611   \n",
       "11  CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...      24942   316029   \n",
       "12  CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...      24940   153400   \n",
       "13  CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...      24940   512365   \n",
       "14  CEN.PK2 - MAT alpha ::: pMODKan-HO-pACT1-ZEV4 ...      24940   512366   \n",
       "\n",
       "                    type      location  \n",
       "0   Yeast Glycerol Stock    M80.7.8.56  \n",
       "1            Yeast Plate     DFP.6.3.7  \n",
       "2   Yeast Competent Cell   M80C.2.15.9  \n",
       "3   Yeast Competent Cell  M80C.2.15.75  \n",
       "4   Yeast Competent Cell  M80C.2.15.76  \n",
       "5   Yeast Competent Cell   M80C.3.0.26  \n",
       "6   Yeast Competent Cell   M80C.3.0.64  \n",
       "7   Yeast Competent Cell   M80C.3.1.17  \n",
       "8   Yeast Glycerol Stock    M80.5.8.56  \n",
       "9   Yeast Competent Cell   M80C.0.2.43  \n",
       "10  Yeast Glycerol Stock    M80.5.8.55  \n",
       "11  Yeast Competent Cell   M80C.2.2.53  \n",
       "12  Yeast Glycerol Stock    M80.5.8.54  \n",
       "13  Yeast Competent Cell   M80C.3.3.62  \n",
       "14  Yeast Competent Cell   M80C.3.3.63  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "df = builddf[builddf.permutation == 0]\n",
    "\n",
    "df['dna_name'] = [aq.Sample.find(x).name for x in df.dna]\n",
    "\n",
    "df.to_csv(\"build_plan.csv\")\n",
    "\n",
    "display.display(df[df.step == 1])\n",
    "\n",
    "fragments = {}\n",
    "for _, row in df[df.step == 1].iterrows():\n",
    "    fragments.setdefault(row.dna, 0)\n",
    "    fragments[row.dna] += 1\n",
    "\n",
    "num_transformations = len(df[df.step == 1])\n",
    "print(\"Number of transformations: \" + str(num_transformations))\n",
    "\n",
    "print('Fragment Usage')\n",
    "display.display(fragments)\n",
    "\n",
    "print(\"Fragment Locations\")\n",
    "item_rows = []\n",
    "for fid in fragments:\n",
    "    f = db.sess.Sample.find(fid)\n",
    "    items = db.find_dna_items(fid)\n",
    "    for item in items:\n",
    "        row = {\n",
    "            'sample_name': f.name,\n",
    "            'sample_id': f.id,\n",
    "            'item_id': item.id,\n",
    "            'type': item.object_type.name,\n",
    "            'location': item.location\n",
    "        }\n",
    "        item_rows.append(row)\n",
    "    if not items:\n",
    "        row = {\n",
    "            'sample_name': f.name,\n",
    "            'sample_id': f.id,\n",
    "            'item_id': \"no item\",\n",
    "            'type': None,\n",
    "            'location': 'no item'\n",
    "        }\n",
    "        item_rows.append(row)\n",
    "item_df = pd.DataFrame(item_rows)\n",
    "display.display(item_df)\n",
    "\n",
    "\n",
    "item_rows = []\n",
    "parent_ids = {}\n",
    "for _, row in df[df.step == 1].iterrows():\n",
    "    parents = row.parent\n",
    "    parents = [p for p in parents if 'TRASH' not in p[1]]\n",
    "    assert len(parents) == 1\n",
    "    parent_id = parents[0][0]\n",
    "    parent_ids.setdefault(parent_id, 0)\n",
    "    parent_ids[parent_id] += 1\n",
    "    \n",
    "print('Yeast Usage')\n",
    "display.display(parent_ids)\n",
    "    \n",
    "print(\"Yeast Locations\")\n",
    "yeast_rows = []\n",
    "for sid in parent_ids:\n",
    "    sample = db.sess.Sample.find(sid)\n",
    "    items = db.find_yeast_items(sid)\n",
    "    for item in items:\n",
    "        row = {\n",
    "            'sample_name': sample.name,\n",
    "            'sample_id': sample.id,\n",
    "            'item_id': item.id,\n",
    "            'type': item.object_type.name,\n",
    "            'location': item.location\n",
    "        }\n",
    "        yeast_rows.append(row)\n",
    "    if not items:\n",
    "        row = {\n",
    "            'sample_name': sample.name,\n",
    "            'sample_id': sample.id,\n",
    "            'item_id': \"no item\",\n",
    "            'type': 'none',\n",
    "            'location': 'no item'\n",
    "        }\n",
    "        yeast_rows.append(row)\n",
    "yeast_df = pd.DataFrame(yeast_rows)\n",
    "display.display(yeast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "martial-tonight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-a1144f363ee3>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['transformations'] = transformations\n"
     ]
    }
   ],
   "source": [
    "transformations = []\n",
    "for _, row in df.iterrows():\n",
    "    if isinstance(row.parent, list):\n",
    "        parent_id = row.parent[0][0]\n",
    "    else:\n",
    "        parent_id = row.parent\n",
    "    dna_id = row.dna\n",
    "    transformation = (parent_id, dna_id)\n",
    "    transformations.append(transformation)\n",
    "    \n",
    "df['transformations'] = transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "preceding-mobile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24943 , 36445\n",
      "33811 , 36353\n",
      "24943 , 36448\n",
      "24942 , 36451\n",
      "24940 , 36447\n",
      "24942 , 36446\n",
      "24942 , 36450\n",
      "33811 , 36339\n",
      "33811 , 36332\n"
     ]
    }
   ],
   "source": [
    "todays_transformations = list(set(df[df['step'] == 1].transformations))\n",
    "\n",
    "rows = []\n",
    "for parent_id, plasmid_id in todays_transformations:\n",
    "    parent = aq.Sample.find(parent_id)\n",
    "\n",
    "    plasmid = aq.Sample.find(plasmid_id)\n",
    "    alt_plasmid = aq.Sample.find_by_name(plasmid.name + ' (v2)')\n",
    "    if alt_plasmid:\n",
    "        plasmid = alt_plasmid\n",
    "        \n",
    "    print(parent_id, \",\", plasmid.id)\n",
    "    \n",
    "    items = aq.Item.where({'sample_id': plasmid.id, 'object_type_id': aq.ObjectType.find_by_name(\"Fragment Stock\").id})\n",
    "    items = [i for i in items if i.location != 'deleted']\n",
    "    \n",
    "    \n",
    "    rows.append({\n",
    "        'parent': parent_id,\n",
    "        'dna': plasmid.id,\n",
    "        'items': [(item.id, item.location) for item in items]\n",
    "    })\n",
    "    \n",
    "pd.DataFrame(rows).to_clipboard()\n",
    "#     print(plasmid.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "boolean-lingerie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unverified PCR Fragment\n",
      "M20.23.13.67\n",
      "__Part\n",
      "Part of Collection\n",
      "__Part\n",
      "Part of Collection\n",
      "__Part\n",
      "Part of Collection\n",
      "Gel Slice\n",
      "deleted\n",
      "Fragment Stock\n",
      "M20.24.1.31\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
