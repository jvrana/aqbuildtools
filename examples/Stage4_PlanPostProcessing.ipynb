{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquarium Plan post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': {'aquarium': <AqSession(name=None, AqHTTP=<AqHTTP(user='vrana', url='http://52.27.43.242')>), parent=4491238136)>,\n",
       "  'benchling': <benchlingapi.session.Session at 0x138075250>,\n",
       "  'registry': <aqbt.aquarium.registry.LabDNARegistry at 0x138077760>}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# login to Benchling & Aquarium\n",
    "from aqbt.tools import config_to_sessions\n",
    "from aqbt.tools import parse_config\n",
    "import toml\n",
    "\n",
    "def config(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        return parse_config(toml.load(f))\n",
    "\n",
    "\n",
    "def sessions(config):\n",
    "    return config_to_sessions(config)\n",
    "\n",
    "\n",
    "sessions = sessions(config('config.toml'))\n",
    "\n",
    "benchling = sessions['default']['benchling']\n",
    "registry = sessions['default']['registry']\n",
    "session = sessions['default']['aquarium']\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_ID = 39491\n",
    "# http://52.27.43.242//plans?plan_id=39388\n",
    "# session.Plan.find(39380)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-08-03T13:13:59.000-07:00'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan = session.Plan.find(PLAN_ID)\n",
    "plan.created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [optional] Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import networkx as nx\n",
    "\n",
    "def add_pour_gel(planner):\n",
    "    print(\"Adding pour gels\")\n",
    "    for op in planner.operations:\n",
    "        if op.operation_type.name == 'Run Gel':\n",
    "            fv = op.input('Gel')\n",
    "            preds = planner.get_fv_predecessors(fv)\n",
    "            if not preds:\n",
    "                pour_gel = planner.create_operation_by_name(\"Pour Gel\")\n",
    "                planner.quick_wire(pour_gel, op)\n",
    "                \n",
    "def add_gblock_seq(planner):\n",
    "    print(\"Adding gBlock sequences\")\n",
    "    for op in planner.operations:\n",
    "        if op.operation_type.name == 'Order gBlock Fragment':\n",
    "            fv = op.input('Bases')\n",
    "            fv.value = op.outputs[0].sample.properties['Sequence']\n",
    "            \n",
    "def needs_seq_results(planner):\n",
    "    print(\"Setting glycerol stock\")\n",
    "    for op in planner.operations:\n",
    "        if op.operation_type.name == 'Make Glycerol Stock':\n",
    "            fv = op.input('Needs Sequencing Results?')\n",
    "            fv.value = 'Yes'\n",
    "            \n",
    "def urgent_primer(planner):\n",
    "    print(\"Setting urgent primers\")\n",
    "    for op in planner.operations:\n",
    "        if op.operation_type.name == 'Order Primer':\n",
    "            fv = op.input('Urgent?')\n",
    "            fv.value = 'yes'\n",
    "            \n",
    "def add_missing_synthesized_fragments(input_file, planner):\n",
    "    print(\"Adding missing synthesized fragments\")\n",
    "    name_to_goal = {}\n",
    "\n",
    "    for g in input_file['GOALS']:\n",
    "        name_to_goal[g['SAMPLE']['query']['name']] = g\n",
    "\n",
    "    fragment_stock = session.SampleType.find_by_name('Fragment Stock')\n",
    "\n",
    "    missing_op = []\n",
    "    for op in planner.operations:\n",
    "        if op.operation_type.name == 'Assemble Plasmid':\n",
    "            out = op.outputs[0].sample.name\n",
    "            inputs = [fv.sample.name for fv in op.inputs]\n",
    "\n",
    "            goal = name_to_goal[out]\n",
    "            g = nx.DiGraph()\n",
    "            g.add_edges_from(goal['EDGES'])\n",
    "            expected_inputs = list(g.predecessors(out))\n",
    "            missing = set(expected_inputs).difference(set(inputs))\n",
    "\n",
    "            missing = missing.difference(['DH5alpha'])\n",
    "            missing_op.append((op, missing))\n",
    "    \n",
    "    all_missing = functools.reduce(lambda x, y: x.union(y), [m[1] for m in missing_op])\n",
    "    \n",
    "    planner.browser.where({'name': list(all_missing)}, model_class='Sample')\n",
    "    \n",
    "    # we've already handled DH5alpha...\n",
    "    for op, missing in missing_op:\n",
    "        for m in missing:\n",
    "            if 'synthesized' in m.lower():\n",
    "                print('\\t' + m)\n",
    "                sample = planner.browser.where({'name': m}, model_class='Sample')[0]\n",
    "                assert sample\n",
    "                fv = planner.set_input_field_value_array(op, 'Fragment', sample, container=fragment_stock)\n",
    "                _ops = planner.chain('Order gBlock Fragment', 'Rehydrate Fragment', fv)\n",
    "                planner.set_field_value_and_propogate(_ops[0].outputs[0], sample)\n",
    "            else:\n",
    "                raise Exception(\"missing {}\".format(m))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAN 39491\n",
      "Plant TF__1596484868_(Terrarium v0.1.5)\n",
      "2020-08-03T13:13:59.000-07:00\n",
      "2020-08-03T13:14:10.000-07:00\n",
      "loading planner...\n",
      "planner loaded...\n",
      "Adding missing synthesized fragments\n",
      "\tSynthesized_PlantTF_2020_Campaign__fdca00f2\n",
      "\tSynthesized_PlantTF_2020_Campaign__7ca02d59\n",
      "\tSynthesized_PlantTF_2020_Campaign__3478329a\n",
      "\tSynthesized_PlantTF_2020_Campaign__3478329a\n",
      "\tSynthesized_PlantTF_2020_Campaign__bfefbb49\n",
      "\tSynthesized_PlantTF_2020_Campaign__fdca00f2\n",
      "\tSynthesized_PlantTF_2020_Campaign__bfefbb49\n",
      "\tSynthesized_PlantTF_2020_Campaign__7ca02d59\n",
      "\tSynthesized_PlantTF_2020_Campaign__64fd711f\n",
      "\tSynthesized_PlantTF_2020_Campaign__bfefbb49\n",
      "\tSynthesized_PlantTF_2020_Campaign__64fd711f\n",
      "\tSynthesized_PlantTF_2020_Campaign__3478329a\n",
      "\tSynthesized_PlantTF_2020_Campaign__2356ca0e\n",
      "\tSynthesized_PlantTF_2020_Campaign__64fd711f\n",
      "\tSynthesized_PlantTF_2020_Campaign__2356ca0e\n",
      "\tSynthesized_PlantTF_2020_Campaign__fdca00f2\n",
      "Adding pour gels\n",
      "Adding gBlock sequences\n",
      "Setting glycerol stock\n",
      "Setting urgent primers\n",
      "optimizing...\n",
      "splitting plans...\n",
      "\tsplit into 2 plans\n",
      "Saving plan to server. Please be patient.\n",
      "\tPlan: Part 1/2: Plant TF__1596484868_(Terrarium v0.1.5)\n",
      "\tNumOps: 173\n",
      "\tprettifying...\n",
      "\thttp:/52.27.43.242/plans?plan_id=39492\n",
      "Saving plan to server. Please be patient.\n",
      "\tPlan: Part 2/2: Plant TF__1596484868_(Terrarium v0.1.5)\n",
      "\tNumOps: 96\n",
      "\tprettifying...\n",
      "\thttp:/52.27.43.242/plans?plan_id=39493\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydent.planner import Planner\n",
    "\n",
    "with open('dirt.io.json', 'r') as f:\n",
    "    input_file = json.load(f)\n",
    "    \n",
    "split_plans = []\n",
    "with session.with_cache(timeout=120) as sess:\n",
    "    print(\"PLAN {}\".format(PLAN_ID))\n",
    "    plan = sess.Plan.find(PLAN_ID)\n",
    "    print(plan.name)\n",
    "    print(plan.created_at)\n",
    "    print(plan.updated_at)\n",
    "    \n",
    "    print('loading planner...')\n",
    "    planner = Planner(plan)\n",
    "    print('planner loaded...')\n",
    "    \n",
    "    add_missing_synthesized_fragments(input_file, planner)\n",
    "    add_pour_gel(planner)\n",
    "    add_gblock_seq(planner)\n",
    "    needs_seq_results(planner)\n",
    "    urgent_primer(planner)\n",
    "    \n",
    "    print(\"optimizing...\")\n",
    "    planner.optimize()\n",
    "    \n",
    "    print(\"splitting plans...\")\n",
    "    split_plans = planner.split()\n",
    "    print('\\tsplit into {} plans'.format(len(split_plans)))\n",
    "    \n",
    "    for i, p in enumerate(split_plans):\n",
    "        p.name = 'Part {}/{}: {}'.format(i+1, len(split_plans), plan.name)\n",
    "        print('Saving plan to server. Please be patient.')\n",
    "        \n",
    "        print('\\tPlan: {}'.format(p.name))\n",
    "        print('\\tNumOps: {}'.format(len(p.operations)))\n",
    "        print('\\tprettifying...')\n",
    "        p.prettify()\n",
    "        p.save()\n",
    "        print('\\t' + p.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fragment_stocks(session, sample_id):\n",
    "    return session.query({\n",
    "        '__model__': \"Item\",\n",
    "        '__query__': {\n",
    "            'sample_id': sample_id,\n",
    "            'object_type': {\n",
    "                '__query__': {\n",
    "                    'name': 'Fragment Stock'\n",
    "                }\n",
    "            },\n",
    "            'location': {\n",
    "                '__not__': 'deleted'\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "with session.with_cache(timeout=60) as sess:\n",
    "    plan = sess.Plan.find(39493)\n",
    "    planner = Planner(plan)\n",
    "    to_remove = []\n",
    "    for op in planner.operations:\n",
    "        if op.operation_type.name == 'Stitch by Overlap Extension':\n",
    "            to_remove.append(op)\n",
    "            successor = planner.get_fv_successors(op.outputs[0])[0]\n",
    "            items = find_fragment_stocks(sess, successor.child_sample_id)\n",
    "            planner.set_field_value(successor, item=items[0])\n",
    "            planner.remove_wire(op.outputs[0], successor)\n",
    "    planner.remove_operations(to_remove)\n",
    "    planner.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mplanner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_operations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpydent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/aqbt/lib/python3.8/site-packages/pydent/planner/planner.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "planner.remove_operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydent.models.inventory.Item at 0x139cd9f00>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session.with_cache(timeout=60) as sess:\n",
    "    print('saving...')\n",
    "    plan = sess.Plan.find(39489)\n",
    "    planner = Planner(plan)\n",
    "    status = set(op.status for op in planner.operations)\n",
    "    plan.status = None\n",
    "    plan.folder = 'SD2 Build'\n",
    "    planner.save()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydent import Planner\n",
    "\n",
    "with session.with_cache() as sess:\n",
    "    \n",
    "    planner = Planner(sess.Plan.find(39488))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "seqs = []\n",
    "\n",
    "with session.with_cache() as sess:\n",
    "    \n",
    "    for plan_id in [39492, 39493]:\n",
    "        planner = Planner(sess.Plan.find(plan_id))\n",
    "\n",
    "        for op in planner.operations:\n",
    "            if op.operation_type.name == 'Order gBlock Fragment':\n",
    "                seq_str = op.outputs[0].sample.properties['Sequence']\n",
    "                assert seq_str == op.inputs[0].value\n",
    "                seq = SeqRecord(Seq(seq_str))\n",
    "                seq.id = op.outputs[0].sample.name\n",
    "                seqs.append(seq)\n",
    "\n",
    "with open('syndna.fasta', 'w') as f:\n",
    "    SeqIO.write(seqs, handle=f, format='fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15560640732265427\n",
      "3.1258278145695337\n",
      "2.066147859922181\n",
      "1.7537437603993318\n",
      "23.106976744186046\n",
      "7.8264150943396205\n",
      "23.824390243902442\n",
      "22.755555555555556\n",
      "24.851612903225814\n",
      "22.728571428571428\n",
      "23.7\n",
      "23.53548387096774\n",
      "8.022471910112364\n",
      "23.03030303030303\n"
     ]
    }
   ],
   "source": [
    "from dasi.utils.sequence.sequence_complexity import DNAStats\n",
    "\n",
    "for seq in seqs:\n",
    "    stats = DNAStats(str(seq.seq), 14, 20, 20)\n",
    "    print(stats.cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "with open('design.out.json', 'r') as f:\n",
    "    design_out = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__name__': 'SHARED_SYNTHESIZED_FRAGMENT', '__index__': 179, '__type__': 'molecule', '__meta__': {}, 'sequence': {'bases': 'ATGGGTACCCGCCCATATGCTTGCCCTGTCGAGTCCTGCGATCGCCGCTTTTCTCGCCACGCCAATCTTACCCGCCATATCCGCATCCATACCGGTCAGAAGCCCTTCCAGTGTCGAATCTGCATGCGTAACTTCAGTCGTAATGCGAACCTTGTGCGCCACATCCGCACCCACACAGGATCCCAAAAGCCGTTCCAATGTCGGATCTGTATGCGGAACTTTAGTCGAAAGGCCGACCTGAGGCGTCACATTCGCACGCACACCGGCGAGAAGCCTTTTGCCTGTGACATTTGTGGGAGGAAGTTTGCCAGGAAGGGCGACCTCAAGAGGCATACCAAAATCCATACAGGTTAGGCGAATTTCTTATGATTTATGATTTTTATTATTAAATAAGTTATAAAAAAAATAAGTGTATACAAATTTTAAAGTGACTCTTAGGTTTTAAAACGAAAATTCTTATTCTTGAGTAACTCTTTCCTGTAGGTCAGGTTGCTTTCTCAGGTATAGCATGAGGTCGCTCTTATTGACCACACCTCTACCGGCATGCCGAGCAAATGCCTGCAAATCGCTCCCCATTTCTGATACCGTCGACCTCGAGTCA', 'length': 601, 'name': 'pMOD8_Backbone_weak_exp_strong_ad_zev', 'id': '<unknown id>', 'annotations': [{'start': 0, 'end': 351, 'strand': 1, 'color': '#0d7dc9', 'name': 'Zev4', 'type': 'Engineered_Regio'}, {'start': 351, 'end': 354, 'strand': 1, 'color': '#87ac24', 'name': 'Stop codon', 'type': 'Engineered_Regio'}, {'start': 354, 'end': 579, 'strand': 1, 'color': '#509dc9', 'name': 'tADH1', 'type': 'Terminator'}, {'start': 579, 'end': 0, 'strand': 1, 'color': '#4458da', 'name': 'TS', 'type': 'misc_feature'}], 'customFields': {}, 'isCircular': False}, 'used_in_assemblies': [{'design_key': '016ad861-af14-4b0c-b603-a81b405578b9', 'assembly': 0}, {'design_key': '016ad861-af14-4b0c-b603-a81b405578b9', 'assembly': 1}, {'design_key': '016ad861-af14-4b0c-b603-a81b405578b9', 'assembly': 2}, {'design_key': '865261e9-5893-4095-845d-aa129f94a928', 'assembly': 0}, {'design_key': '865261e9-5893-4095-845d-aa129f94a928', 'assembly': 1}, {'design_key': 'd8b31f69-62f5-4b44-b98a-c628c5a95825', 'assembly': 0}, {'design_key': 'd8b31f69-62f5-4b44-b98a-c628c5a95825', 'assembly': 1}, {'design_key': 'd8b31f69-62f5-4b44-b98a-c628c5a95825', 'assembly': 2}], 'used_as_input_to_reactions': [72, 94, 84, 86, 101, 73, 87, 104], 'used_as_output_to_reactions': [164]}\n"
     ]
    }
   ],
   "source": [
    "seqs = []\n",
    "\n",
    "for m in design_out['molecules']:\n",
    "    if m['sequence']['bases'].lower() == seq.lower():\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasi.utils.sequence.sequence_complexity import DNAStats\n",
    "\n",
    "seq = 'AGTGTCCCTTAACCAGATTCGAAAAGCGGCCCTTAACCAGATTCGAAAAGCGGCAGTAATCTTTCGGTCTACGCAACTGACTAGCTAACTATCGTTTCGACTGGGCCAAGTAATCGGCCGACTTACGCAACTAGGTGTCAGTCTATGACACCGTTGTACTGGAGTAATCTATGCAGTTACGCAACTAAGATATAAGGCGCCTTTCCTGCCTCGCAAAGTAATCACGGTAGTTACGCAACTTGGTGAGATGGAAGGCCATCACCGGACGAGAGTAATCGCATCCTCTACGCAACTCTACCCGTACTGCTCCCTTGAGATAGCAAAAGTAATCAATACGCCTACGCAACTTGCCGTGTGCTGTGTTCAACACGATCGTCTAAAGTGAAAGTCGAGCTCGGTACAAAGTGAAAGTCGAGCTCGGTACGATCCT'\n",
    "\n",
    "stats = DNAStats(seq, 14, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.29\n",
      "1.48\n",
      "2.07\n",
      "7.83\n",
      "8.02\n",
      "36.29\n",
      "80.99\n",
      "3.13\n",
      "1.75\n",
      "7.83\n",
      "8.02\n",
      "2.07\n",
      "1.75\n",
      "7.83\n",
      "8.02\n",
      "1.75\n",
      "1.48\n",
      "81.16\n",
      "7.83\n",
      "81.16\n",
      "3.13\n",
      "3.13\n",
      "7.83\n",
      "7.83\n",
      "2.07\n",
      "37.35\n",
      "1.48\n",
      "7.83\n",
      "8.02\n",
      "7.83\n"
     ]
    }
   ],
   "source": [
    "for d in design_out['designs'].values():\n",
    "    for a in d['assemblies'][:1]:\n",
    "        print(a['cost']['max synthesis complexity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
